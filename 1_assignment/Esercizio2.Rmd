---
title: "Esercizio2"
author: "Michele Luca Puzzo"
date: "11/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## 2.1

To have a legit density I have to impose that the approximating density is greater than 0 for each x belonging to the support $S_X = [0,1]$. Moreover the integral of the approximating density over all the support has to be equal to 1. 

$\hat{f}(x, ðš¹) > 0 \hspace{0.2cm} \forall x \in S_x$

The indicator function can be equal to 0 or 1 and h is a length so it is greater than zero so:

$$\sum_{j=1}^N \frac{\pi_j}{h} \mathbb{I(x \in B_j)}>0 \Rightarrow \pi_j > 0 \hspace{0.2cm} \forall j \in \{1,..,N\}$$
$\int_{\mathbb {R}}\hat{f}(x, ðš¹)dx = 1$

I exploit the additivity of the integral respect to the extremes:

 $$\int_{0}^{1}\sum_{j=1}^N \frac{\pi_j}{h} \mathbb{I(x \in B_j)} dx = \int_{0}^{h}\sum_{j=1}^N \frac{\pi_j}{h} \mathbb{I(x \in B_j)} dx + \int_{h}^{2h}\sum_{j=1}^N \frac{\pi_j}{h} \mathbb{I(x \in B_j)} dx + ... + \int_{1-h}^{1}\sum_{j=1}^N \frac{\pi_j}{h} \mathbb{I(x \in B_j)} dx = \frac{\pi_1}{h} \cdot h + \frac{\pi_2}{h}\cdot h+ ...+\frac{\pi_N}{h}\cdot h = 1$$
In  conclusion the constraints that we have obtained, given a fixed h, over the parameter vector ($\pi_1, \pi_2, ... \pi_N$) are:

- $\pi_j > 0 \hspace{0.2cm} \forall j \in \{1,..,N\}$

- $\sum_{j=1}^N \pi_j= 1$ 

So we have obtained that each parameter $\pi_j$ has to be greater than zero and their sum has to be equal to one.

## 2.2

We have implemented the approximating density using a *for loop* and an *if-else condition* to realize the indicator function. When we find the bin corresponding to the x we interrupt the cycle, because it is useless to check all the bins.
In our convention a generic bin is an interval left closed and right open except the last one, for example the first is [0,h). 
The number of bins N has to be an integer number: we have used the function *ceiling* knowing that the last bin could be shorter because 1/h could be not integer.
  

```{r}
#pigreco is a list of N parameters, h is a fixed parameter
approx_f <- function(h, x, pigreco){
  
  #input:
  #h: length of the bin
  #x: point in which we want to compute the function
  #pigreco: vector of parameter 
  
  #output: approximating function computed in x
  
  #computing number of bins, the last bin could be shorter
  N = ceiling(1/h) 
  
  #I start from zero to consider also the first bin 
  for (i in 0:N-1){
    
    #condition to check to what bin x belongs to
    #my arbitrary decision is that a bin is right open and left closed
    #so they are like [0,h)
    if((x >= i*h) & (x < (i+1) * h)){ 
      
      #approximating function 
      return(pigreco[i+1]/h)
      
      #when I find the right bin it is useless to check also the others
      break
      
    }else{
      #for the last bin is also right closed: [1-h,1] and
      #with the previous cycle I am not able to catch the output of the function when x is equal to 1
      if(x==1){                   
        return(pigreco[length(pigreco)]/h)
      }
    }
  }
}
```

Then we have picked a value for h, 0.1, and ten parameters $\pi_j$ that respect their constraints to check if our definition of approximating density makes sense. We have plotted the approximating function with a plot of *type = h* because in this way we can better visualize its shape that is just like a histogram, and then we have add the step with a *for loop* and the function *segments*. The area behind the steps is 1 thanks to the constraint that $\sum_{j=1}^N \pi_j= 1$.

```{r}
#given h
h= 0.1 

#arbitrary parameter vector that respect its constraints. I pick all positive numbers
pigreco <- c(0.08,0.13,0.07,0.07,0.12,0.10,0.10,0.10,0.06,0.17)

#check if the constraints are verified
cat("The sum of my arbitrary parameter must be", sum(pigreco))

#points in which we compute the approximating function
x <- seq(0, 1, 0.01)

#approximating function 
f_hat = sapply(x, function(x) approx_f(h, x, pigreco)) 

#plot: type="h" allow to understand better its shape
plot(x, f_hat, xlim=c(0,1), col="darkgreen", type = "h", main = "approximating PDF", ylab = "approx f") 

#I add the segments to visualize better the steps
segments(0.9, pigreco[10]/h, 1, pigreco[10]/h, col = "orchid", lwd = 3)
for(i in 0:9){
  segments(i*h,pigreco[i+1]/h, i*h + 0.09,pigreco[i+1]/h, col = "orchid", lwd = 3)
}
```
Just to have a visualization of what we are doing, we keep going with this tiny example and we have also tried to plot its CDF. Since the approximating density is a stepwise function, we expect that also its CDF is stepwise. Instead to use the function *integrate*, we have done the cumulative sum of the parameter vector because the area under each step is equal to $h \cdot \frac{\pi_j}{h} = \pi_j$ so it is like we are summing an area after the other. The difference between two consecutive step, for example j and j+1, is equal to the value of $\pi_{j+1}$. The height of the last step is 1. 

```{r}
approx_F <- function(pigreco){
  
  #input: parameter vector
  #output: plot of the approximating CDF 
  
  #I compute CDF doing the cumulative sum. 
  #I add one at the end just to have a vector of length 101 as x
  f_grande <- c(rep(cumsum(pigreco), each = 10), 1)
  
  plot(x,f_grande, type = "p", col = "salmon", lwd = 1, pch= 19, main = "approximating CDF", ylab="approx F")
  
  #with par I admit another plot in the same figure
  par(new=TRUE)
  plot(x,f_grande, type = "h", col = "darkgreen", lwd = 1, ylab="")
  
  #plot the horizontal line to visualize the first, second and third quartile
  abline(0.25,0, col = "orchid", lwd = 2)
  text(0.1,0.3,"p = 0.25")
  
  abline(0.5,0, col = "orchid", lwd = 2)
  text(0.1,0.55,"p = 0.5")
  
  abline(0.75,0, col = "orchid", lwd = 2)
  text(0.1,0.8,"p = 0.75")
}
#computing the CDF for my example
approx_F(pigreco)
```

To compute the approximating quantile function we need a vector that contains for each step its starting point, so we want to know that first step starts at x equals to zero, second step starts at x equals to h and so on. 
We use the cumulative sum to compute this vector, that we have called **h_list**. An element of this vector, h_list[i], is the output of the function because it is equal to the smallest value x such that the CDF is at least p (the wanted given area), that is the definition of the quantile function. $Q(p) = \hat{F}_x(h\_list[i]) \ge p$. 

We are able to compute in this way the quantile function because the approximating density is a stepwise function. From the plot of the quantile function of our example we can observe that is also stepwise and the lenght of each step reflect the height of the step in the approximating density. 
Indeed the longer step in the quantile function it is the one corresponding to the last step in the approximating density that is the highest. 

```{r}
approx_quantil <- function(h, p, pigreco){
  #input:
  #h: length of the bin
  #p: tail area
  #pigreco: parameter vector
  
  #output: quantile of p
  
  #compute the cumulative sum of the vector of parameters pigreco
  cdf <- cumsum(pigreco) 
  
  #number of bins
  N = ceiling(1/h)
  
  #In this case the quantile function will be always equal to the start of the step, so I have also compute the cumsum of the length of the bins 
  h_list = rep(h, N)             
  h_list = cumsum(h_list)
  
  #until the first height the function will be zero
  if (p <= pigreco[1]){       
    return(0)
    
  }else{
    
    for (i in 1:(N-1)){
      
      #I look for the first bin that cover the given tail area  
      if((p > cdf[i]) & (p <= cdf[i+1])){
        
        #it will return the starting point of the bin
        return(h_list[i]) 
        
        #when I find the right bin it is useless check also the others
        break
      }
    }
  }
}

#compute and plot the quantile function for my example 
quantili = sapply(x, function(x) approx_quantil(h, x, pigreco))
plot(x, quantili, xlim=c(0,1), ylim = c(0,1), col="purple", type = "p", pch = 19, main = "approximating Quantile Function", ylab = "x", xlab="p")

```

## 2.3

As $(\alpha, \beta)$, parameter of the Beta distribution we have chosen the couple (2,2). We have preferred this couple respect to (5, 1) for example because in this second case for x near to zero, we would obtain values for $\pi$ too near to zero, like $1 \cdot 10^{-15}$ and we do not know if the first constraint $\pi_j > 0 \hspace{0.2cm} \forall j$ will be respected, maybe not for numerical issues, so we have chosen a more safe couple, (2,2). 

To compute each element of the parameter vector we have not computed the integral, but we have made the difference between two function *pbeta* computed in two consecutive step' starting point like 0 and h or 1-h and 1. In this way the elements of the parameter vector are equal to the area under the true density in the interval of length h. We can define them in this way because we are working under perfect information, meaning that we can access the true model.

```{r}
param <- function(h, a = 2, b = 2){
  #input:
  #h: length of the bin
  #a,b: alpha and beta of the beta function
  
  #output: parameter vector
  
  #number of bins
  N = ceiling(1/h)
  
  #I compute the cumsum of the length of the bin so to have values because 
  #I have to compute pbeta function and I need starting and end point
  h_list = c(0, rep(h, N))
  h_list <- cumsum(h_list)
  
  #initialize the parameter vector
  pigreco = c(length(N))
  
  for (i in 1:N){
    
    #doing the following difference I am computing the integral of the i-th bin
    #I am computing the difference between two areas and the result is 
    #the area in the interval of the bin 
    pigreco[i] <- pbeta(h_list[i+1],a,b) - pbeta(h_list[i],a,b)
  }
  
  #parameter vector
  return(pigreco)
}

#beta(5,1) 
p <- param(0.001,5,1)
cat("If we had chosen beta(5,1) the first parameter is: ", p[1])

#beta(2,2) 
p <- param(0.001,2,2)
cat("We had chosen beta(2,2) so the first parameter is: ", p[1], "It is a bit higher")
```

To check if we have defined in the right way the approximating quantile and the parameter vector, we compute the difference between the true and the approximating quantile function with difference value for h. We can observe that if we increase h, the difference is greater, as expected because with h larger we are taking a coarser approximation of the true function.

```{r}
#sanity check 

cat("The difference between true and approximating quantil function in 0.5 with h = 0.001 is ", qbeta(p = 0.5,2,2) - approx_quantil(h = 0.001,p = 0.5, param(h = 0.001)))

cat("The difference between true and approximating quantil function in 0.5 with h = 0.2 is ", qbeta(p = 0.5,2,2) - approx_quantil(h = 0.1 ,p = 0.5,param(h = 0.1)))

cat("The difference between true and approximating density function in 0.5 with h = 0.001 is ", dbeta(x = 0.5,2,2) - approx_f(h = 0.001, x = 0.5,param(h = 0.001)))

cat("The difference between true and approximating density function in 0.5 with h = 0.1 is ", dbeta(x = 0.5,2,2) - approx_f(h = 0.1, x = 0.5,param(h = 0.1)))
```

Now we have written a function, *wass_dist*, that computes the Wasserstein distance. We compute this integral numerically: we take 1000 points in the interval in which we compute the absolute difference between the two functions and then sum all of them. 
Also here we have observed that the higher is the h, the higher is the Wasserstein distance.

```{r}
#I divide the support [0,1] in 1000 point where I compute the two, true and approximating, quantile function 
x = seq(0,1,0.001)

wass_dist <- function(h, a = 2, b = 2){
  #input:
  #h: length of the bin
  #a,b: alpha and beta of the beta function
  
  #output: Wasserstein distance
  
  return(sum(sapply(x, function(x) abs(qbeta(x, a, b) - approx_quantil(h, x, param(h, a, b))))))
} 


#sanity check 
cat("The Wasserstein distance for h = 0.001 is: ", wass_dist(0.001))
cat("The Wasserstein distance for h = 0.1 is: ", wass_dist(0.1))
cat("The Wasserstein distance for h = 0.5 is: ", wass_dist(0.5))
```

To find  the largest binwidth h such that the Wasserstein distance is smaller than epsilon we have written the function *h_large*. We start from an h for which we are sure that we obtain a distance greater than of the given epsilon. Then we decrease h by 0.001 and try to compute again the distance to check if now the distance is smaller than epsilon and so on and so forth. When we find an $\hat{h}$ which satisfy the inequality we check if there is an h larger than $\hat{h}$ between $\hat{h}$ and ($\hat{h}$ + 0.001). We take the middle point between these two values and check again. We repeat this "bisection method" at most three times to avoid numerical issue. 

```{r}
h_large <- function(h, epsilon, a = 2, b = 2){
  #input:
  #h: is the first h for which I compute the Wasserstein distance
  #epsilon: vector of epsilon that I want analyze
  #a, b: alpha and beta of the beta function
  
  #output:
  #h_l: a vector made by the largest binwidth, one for each epsilon
  
  h_l <- rep(0, length(epsilon))
  c <- 0
  
  #I scan all the vector of epsilon and analyze one at a time
  for (i in epsilon){
    
    #Since I look for the largest h, I have to pick the largest distance 
    #smaller than epsilon
    while (wass_dist(h, a, b) > i){
      
      #For each tentative I decrease h slowly 
      h = h - 0.0001
    }
    
    #counter to stop the bisection method
    t = 0
    
    #I want to check if there is an h bigger respect to that 
    #I have pick
    #at most three iteration for the bisection method
    while ((wass_dist((h + 0.001)/2, a, b) > i) | (t == 3)){
      
      #updating again my h
      h = (h + 0.001) /2
      #updating the counter
      t = t + 1
    }
    #I move the next epsilon
    c <- c +1 
    
    #I save the value of h that I found
    h_l[c] <- h
  }
  
  return(h_l)
}
```

To choose what $\epsilon$'s take in consideration we evaluate the Wasserstein distance for different h to see what values it assumes. Unlike the previous exercise now epsilon is the an absolute error so it can assumes also larger values. We see that for h = 0.08 we obtain an error of 4, that was in our opinion a good starting point for our study. We want to observe how h varies with $\epsilon$ between 4 and 0.1. 
```{r}
cat("The Wasserstein distance for h = 0.08 is: ", wass_dist(0.008))

#values of epsilon for which we want to find the largest h
eps = seq(4, 3.8, -0.1)

#computing the function starting from h = 0.101
h_largest <- h_large(0.008, eps)
```

Now through a plot we visualize the result: we see that the trend of h respect to $\epsilon$ is linear. The slope of the line is positive so when I decrease $\epsilon$ I have to decrease the length of the bin. This behaviour confirms what we expected: to have a small absolute error we have to decrease the length of the bin such we have a finer approximation of the quantile function. 

```{r}
#plot of the trend of the largest binwidth in function of epsilon 
plot(eps, h_largest, main = "Largest binwidth in function of epsilon", xlab = "epsilon", ylab = "h", pch = 19, col = "darkorange")

#I use the function lm just to show that the trend of h as a function of epsilon
#is linear 
fit  <- lm(h_largest~eps)
abline(fit$coefficients[1], fit$coefficients[2], col = "blue", lwd = 2)
```

## 2.4

We are working under perfect information, meaning that we can access/query the true model. We have understood from the previous point that the elements of the parameter vector are areas and they are sorted because for example $\pi_1$ represent the area under the Beta density in the first interval. Furthermore we have observed that with the previous choice of $\pi_j$ we have obtained an optimal approximation of the quantile function. 

For this we have decided to to obtain a new parameter vector in this way: each element will be a sample from the beta distribution multiplied for the length of the interval. It is a similar choice from the previous one, but a bit rougher because now we are taking as $\pi_j$ the area of a rectangle with base equals to h and height the Beta distribution in the first point of the interval. 

We have tried also other initialization of the parameter vector, but the results had too poor quality because the approximation of the quantile function was too rough. 

```{r}
rbeta_scratch <- function(n = 1, range, a = 2, b = 2) {
  #input:
  #n: number of sample
  #range: a vector of length 2, in which I insert the extreme of the interval(along x axis)
  #a,b: parameter of Beta distribution
  
  #output: a point of Beta density(corresponding to an x belonging to range interval)

  #I sample uniformly in the interval range
  uniforme <- runif(1, range[1], range[2])
  
  #I take the corresponding value on Beta density
  dbeta(uniforme, 2, 2)
  
}

parameter_2 <- function(h){
  #input:
  #h: length of the bin
  
  #output:
  #new parameter vector 
  
  N <- ceiling(1/h)
  
  vector(mode = "double", length = N)
  
  t[1] <- rbeta_scratch(1, c(0,h), 2, 2)
  
  for(i in 1:N-1){
    t[i+1] <- rbeta_scratch(1,c(i*h,h*(i+1)),2,2)
  }
  t <- t*h
  return(t/sum(t))
}

#check that the new parameter vector respects the constraints
sum(parameter_2(0.01))
```

Now with the same function of before we compute the new Wasserstein distance and we want to check if at the increasing of h, the distance decreases. 

```{r}
#I divide the support [0,1] in 1000 point where I compute the two, true and approximating, quantile function 
x = seq(0,1,0.001)

wass_dist_2 <- function(h, a = 2, b = 2){
  #input:
  #h: length of the bin
  #a,b: alpha and beta of the beta function
  
  #output: Wasserstein distance
  a = 0
  for(i in x){
    t <- approx_quantil(h, i,parameter_2(h))
    a = a + abs(qbeta(i,2,2) - t)
  }
  return(a)
} 


#sanity check: increasing h the distance increases
cat("The Wasserstein distance for h = 0.001 is: ", wass_dist_2(0.001))
cat("The Wasserstein distance for h = 0.1 is: ", wass_dist_2(0.1))
cat("The Wasserstein distance for h = 0.5 is: ", wass_dist_2(0.5))
```

Since we have computed in a similar way the distances we want to make a comparison. 

```{r}
#We check if the distance that we have computed now if similar to the previous one.

cat("The Wasserstein distance for h = 0.001 is: ", abs(wass_dist(0.001) - wass_dist_2(0.001)))

cat("The Wasserstein distance for h = 0.01 is: ", abs(wass_dist(0.01) - wass_dist_2(0.01)))

cat("The Wasserstein distance for h = 0.1 is: ", abs(wass_dist(0.1) - wass_dist_2(0.1)))
```

We observe that for small h, we almost obtain the same values so we expect the same behaviour of h at varying of $\epsilon$.
